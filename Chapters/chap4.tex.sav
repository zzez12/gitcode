\chapter{分割问题在定格动画制作中的应用\footnote{本章内容主要发表在：A Video-based Interface for Hand-Driven Stop Motion Animation Production. IEEE Computer Graphics and Applications, 2013.}}

\section{问题介绍}
在前面两章中，我们讨论了基于先验知识的二维和三维分割问题。在本章中，我们考虑分割问题在视频制作中的应用。近些年来，随着各种视频采集手段的更新和发展，人们更容易获取到各类不同的视频数据，对视频数据的分析和编辑也成为计算机领域的一个重要问题。在视频制作中，有一种叫做定格动画的特殊动画制作方法。该方法通过逐格地拍摄对象后再使之连续放映，利用人类的视觉暂留特性，使人们看到会动的人物或者活动影像。

传统的定格动画制作过程是十分耗时耗力的。定格动画师需要手动将需要移动的对象每次进行很少的移动，然后对其固定后拍摄一张静态图像，然后再进行少量移动再继续拍摄静态图像，同时在静态图像中不能出现动画师的辅助固定工具。所以对于一段完整的运动轨迹来说，需要动画师预先设置好其每个对象的运动方向、位置，仔细规划每一格的具体静态图像。显然，这一制作过程对于一般的用户并不是直观和易用的。

传统定格动画制作的另一缺陷是，在许多场景中，拍摄对象需要使用大量的支撑辅助工具进行固定，而这些工具的引入也会对拍摄物体的部分区域发生遮挡。这些多余的部分和遮蔽的部分有时很难在后处理中去除。近年来使用较多的解决方法是使用专门的器械\cite{shaw2008stop}，如较为细固定杆和较重的底座与拍摄物体连接后进行拍摄，之后使用计算机对其进行后处理以在图像中去掉这些器械。但是，大部分器械都是十分昂贵或沉重的，且难以在一般用户家中使用。而且，固定拍摄对象和辅助器具大部分情况也需要十分专业的知识，特别是对于拍摄对象太重、太脆或很难和器械连接的时候。

\begin{figure*}[t]
\centering  \includegraphics[width=\linewidth]{Pictures/pipeline}\\
  \caption{基于关键帧技术的二次采集过程}\label{fig:pipeline}
\end{figure*}

为了解决这些缺陷，本章内容设计了一种新的基于视频的定格动画生成方法。我们将拍摄动画分为二个阶段（如图~\ref{fig:pipeline}），其中第一阶段动画师用手拿着需要拍摄的物体，对其进行一遍整体连贯的传统视频拍摄，我们希望最终将动画师的手从阶段一得到的视频中去除，从而得到一段完整的无支撑物的物体运动动画。而第二阶段的拍摄则是辅助去除人手并恢复物体遮挡的参考视频。阶段二并不需要连贯的整体视频，仅仅需要拍摄若干关键帧中物体在不同遮挡下的类似运动。利用视频的时空连贯性信息，我们给出了基于这种特殊输入――需要去除人手遮挡的图像分割和补全算法，然后继续利用视频的连贯性，将单帧图像的结果传递给前后其他帧的图像，最终得到完整的动画结果。

\section{相关工作}

\textbf{定格动画制作} 定格动画是一项较为完善的技术\cite{ken2007art,purves2008stop,shaw2008stop}。现在市场上存在许多为不同层次用户设计的制作定格动画的软件，如针对专家级用户的DragonFrame和非专家级用户设计的Stop Motion Pro, iStopMotion 等，然而其内部的技术在近些年来却发展较为缓慢。这些系统大部分都是在物体微小移动的情况下对各个镜头进行单独拍摄\cite{konigsberg1997complete}。虽然本章使用的基于视频的方法很少使镜头每一帧都停下拍摄，但是我们最终希望生成与传统定格动画类似的视频结果。在传统的定格动画制作过程中，由于带有关节的骨架或者陶土制作的物体较为容易固定和摆成各种姿势，这类物体经常被当做拍摄对象，但是这类对象的制作有时也需要某些特殊的制作方法，比如物体需要焊接到某些固定支架上，这对于一般的用户并不十分友好。与其不同的是，本章中的对象主要针对于我们日常生活中经常使用的物品，如茶杯、椅子、灯具等，所以对于一些初次接触我们方法的用户也能较快的上手。

\textbf{基于视频的动画} 在最近的视频处理和运动跟踪技术的发展下，有许多制作非真实感图像和卡通动画的系统\cite{wang2004video,winnemoller2006real}，这些系统可以将输入的一段视频重新风格化为其它不同的特点，得到一段新的动画视频。而与其不同，本章中的定格动画则需要保持原始视频的风格，在最终动画中将支撑物（即手）去除。Barnes等\cite{barnes2008video} 则提出了一套基于视频的剪影动画制作系统。该系统能够追踪二维纸偶在动画师手中的移动轨迹，在渲染中通过将纸偶替换为在数据库中事先存储的模型，直接将动画师的手去除。而在Snake-Toonz系统中\cite{agarwala2002snaketoonz}对二维手绘动画(cel animation)的处理也类似于上述的方法。这类方法的共性是，由于数据库中仅有物体在单一平面中的信息，所以仅能对平面的物体进行处理，当物体进行三维的旋转时，其结果就很难预测。本章中使用的方法则不是基于数据库的，所以可以对更为复杂的三维物体进行操作，甚至可以还原三维物体在周围环境下的不同视觉特点（如图？中的动态镜面反射效果）。

\textbf{视频分割和补全} 本章中关注的一个重点是将动画中的拍摄物体分割出来并对其被手遮挡的部分将其补全。近些年来由许多交互式的视频图像物体提取\cite{li2005video,wang2005interactive,bai2009video}和抠图\cite{agarwala2004keyframe}的技术。这些方法都是设计用来将需要的物体精确地分割出来，而且需要大量的人工交互以达到高精度的需求。而本章中的方法的最终目的是重建出被手遮挡的物体部分，并不需要精确的分割结果，所以在操作过程中并不会给用户带来较大的交互负担。

近些年来的视频补全方法\cite{vijay2009efficient,wexler2007space}很多都运用三维基元，利用视频的时空连续性，将可以得到的不完整部分在其它帧中的对应部分进行填充。这一类方法对于缺失部分为背景区域时十分有效，但是当缺失部分为动态变化的前景物体或者在复杂运动的物体就很难得到理想的结果，其主要原因是在帧与帧之间，物体的拓扑性质可能发生了很大改变。同时，需要补全的部分甚至有可能并不存在于视频片段中。本章使用的方法可以很好的避免这类问题的产生。

\textbf{多输入的图像分割补全和加强} 当输入的图像是多张对同一物体从不同角度或者不同拍摄参数时，我们可以充分利用其共性来分割和补全物体。如文献\cite{agarwala2004interactive,hays2007scene,wilczkowiak2005hole}，其可以利用其他图像中的合适的小块将具有较大洞的图像进行补全。而Agarwala等\cite{agarwala2004interactive}提供了一种数字蒙太奇的框架，将不同的图片组合成为一张新图，呈现出各种不同的艺术效果。本章提出的系统和这类方法有些类似，将两张从两次阶段得到的图像进行组合，然后生成一张新的图像。但是与图像蒙太奇系统处理的对象不同，蒙太奇系统处理的为事先对齐的静态图像，而本章中针对的对象需要对齐在不同时刻的图片，并将补全之后的图片沿着关键帧光滑的传播到其他帧中。

除此之外，本章内容也与现今的一些利用一对有缺陷的图片进行编辑的方法相关。其中这一对图片可以来自于某些特殊设置下，如相机参数不同（如有闪光灯和没有闪光灯\cite{petschnigg2004digital,eisemann2004flash}）、曝光时间\cite{jia2004bayesian,yuan2007image}不同等；这些方法可以在图片进行去噪、细节迁移等应用中发挥作用。而本章的方法则对一对在不同手部遮挡状况下的关键帧图片进行处理。

\section{用户界面与算法概述}
与传统的复杂而沉重的定格动画制作系统不同，我们的系统主要针对于家用物体的定格动画进行设计，这样可以使非专业的用户也可以较快地进行定格动画的制作。我们的数据采集装置为较为简单且便宜的消费级USB网络摄像机（在我们的实验过程中，使用了罗技HD Pro Webcam C910这款摄像头）。由于我们主要关注于物体的运动，所以我们在实验中使用三脚架对摄像头进行了固定。在我们的系统中，我们需要对拍摄物体进行两次运动采集，并且在第二次采集并不需要完全重复第一次采集的所有路径。下面将具体描述我们系统使用的两个采集阶段。

\subsection{两个采集阶段}\label{sec:phases}
\textbf{一次采集阶段} 第一阶段首先采集到没有运动物体以及用户手部等支撑物的系统背景图像。然后用户直接手握需要拍摄的物体，在相机视野中进行其所需要运动的连续变换。在这一过程中，我们的系统允许用户手部抓握物体的部位发生改变，但是这一操作有可能使捕捉到的物体运动轨迹不太连贯，这就需要在后续的动画生成中进行少量的编辑操作。

\begin{figure}[h]
\centering  \includegraphics[width=0.95\linewidth]{Pictures/placement_rules}\\
  \caption{正确的抓握例子（左）与两个错误的抓握例子（中、右）}\label{fig:placement_rules}
  \vspace{3mm}
\end{figure}
在计算机视觉的相关技术中，更为容易对刚性物体进行操作。为了使得系统能够有较高的效率，我们建议用户抓握在拍摄物体的刚性部分，尽量避免手部对非刚性物体部分的遮挡。满足上述条件的采集数据，更容易得到较好的动画结果。为了使得接下来的图像分割个手部去除过程更为高效，我们对用户抓握物体拍摄过程中的方法有一些建议，其重要性依次降低，归纳如下：
\begin{itemize}
  \item 被遮挡区域的面积应当尽量小；
  \item 避免不必要的用户与物体的重叠部分（如在图\ref{fig:placement_rules}中抓住物体的左下脚，而不是如图~\ref{fig:placement_rules}右图）；
  \item 设置合适的光照条件以减少人手部阴影或人体阴影的影响。
\end{itemize}

在进行第二次采集之前，用户需要指定出其感兴趣的区域（region of interest, ROI），即物体所在的大致区域（如图~\ref{fig:pipeline} 中的橙色矩形区域）。这一矩形框仅需用户对最开始的第一帧含有拍摄物体进行指定，然后我们使用运动跟踪技术，将这一区域传播到后续帧之中，用户只需对其进行检验和修正。然后，对物体的运动进行分析，系统将会自动给出一系列关键帧，用户也可以根据其具体需求增加更多关键帧以使后续过程更为准确。一般地，当物体存在较为复杂的运动（如三维旋转）或者物体的抓握方式改变较大时，需要更多的关键帧。

\begin{figure}
\centering  \includegraphics[width=\linewidth]{Pictures/onion_skinning}\\
  \caption{关键帧中物体对齐的界面：吸附后的图像（左），为进行吸附处理的图像（中），两次拍摄得到的物体的边缘图的重叠图（右）}\label{fig:opinon_skinning}
\end{figure}

\textbf{二次采集阶段} 在这一部分，我们将使用一个特殊设计的辅助界面对刚才得到的关键帧进行依次处理。从第一个关键帧开始，用户将对逐个关键帧进行二次采集，并将两次得到的图片进行重叠显示，以使用户确定两次得到的物体处于同一位置。即将拍摄物体放置在摄像头前以使其与第一次得到的图片对齐（如图~\ref{fig:opinon_skinning}）。在这次采集中，用户必须抓握物体的不同区域，以便使物体在第一次拍摄中被遮挡的部分显露出来。为了使得我们后续的计算更加稳定，我们建议用户尽量使在二次遮挡的部位远离第一次视频中的物体遮挡部分。

我们的界面设计思想来源于动画编辑中的透视模式（onion skinning），其将当前摄像头拍摄的图片与当前处理的关键帧进行半透明混合显示（如图~\ref{fig:opinon_skinning}左图）。这一界面对用户判断物体重叠的精确性有着非常大的帮助。同时，我们也使用类似吸附的方式，当二次拍摄的物体与一次关键帧中物体足够接近时，系统将自动对二次拍摄的物体进行形变，以便更快与其对齐。这一吸附功能能够很大程度上减轻用户对齐这一操作所需要的精确性需求。同时，两次拍摄的物体的边缘图的重叠显示也实时在界面中显示（如图\ref{fig:opinon_skinning}右图），帮助用户进行对齐操作。这一透视模式在传统的定格动画\cite{shaw2008stop}和数字动画软件（如Adobe Flash）中也是十分重要的特性。这些特性的应用主要是为了帮助用户降低帧与帧之间运动的幅度，而本章使用这一模式则是为了帮助对齐两帧图像。

我们建议用户在做对齐时尽量与第一次拍摄处于相机的同一侧，而且显示器则位于其正对面。这一设定与在测试6-自由度输入设备的测试任务\cite{zhai1995human} 十分类似。从这一角度看，这一操作可以看作是6-自由度（3个平移方向，3个旋转方向）的物理输入控制器。由于我们提供了较为直观的操作反馈界面，这一操作步骤是比较有效率的。

\subsection{交互式物体分割及人手去除}
在经过两次数据采集后，我们从一次采集中得到了一整段完整视频，从二次采集中得到了若干张已经与一系列关键帧对齐后的图片。在下一步骤中，系统将使用半自动的方式得到图片中的物体、人手的区域位置蒙版（mask），即将每个关键帧中的物体区域，人手区域分割出来。当所有的关键帧都得到这些位置，系统将会关键帧的蒙版结果顺序传递到其前后帧上，最后利用关键帧的补全结果和非关键帧中的掩码蒙版，可以将非关键帧中的手部遮挡部位通过补全后的关键帧中的对于区域进行形变后填充得到，进而得到完整的定格动画（如图~\ref{fig:pipeline}）。

具体地，给定一对关键帧上采集到的图像，系统用过求解一个优化方程，将两张图片进行合成以去除人手部分。如果这一结果中存在错误，用户可以使用笔刷对其直接修正（如图~\ref{fig:kf_seg}），其中笔刷刷过的部位被看作为优化问题中的硬约束。通过优化求解，系统将得到图片上的物体区域蒙版和人手区域蒙版，而这一结果会在用户修正过程中实时更新显示。

需要强调的是，本章系统的目标是生成令人满意的动画视频，虽然需要完整地重建出被遮挡部分物体的图像，但是我们并不需要得到一个精确的物体分割和人手分割结果。实际上，我们得到的人手区域比真实的区域稍微大一些，这是为了去除阴影带来的图像缺陷。一个非完全精确的分割结果对于后续的区域蒙版传播也是足够用的。而且，分割中引入的人工交互并不是特别复杂和繁重，本章中的例子大部分都仅需要少量的“用户笔刷”就能得到令人满意的结果。

最后，还要指出，我们也提供了一个背景笔刷工具，以便用户将在ROI 外的人手和人体或者其他支撑物标记出来，这一部分区域也需要在最终的视频中去除。由于我们在一次采集阶段建议用户避免不必要的物体与人手等的重叠，这些在ROI外的遮挡区域可以使用最开始无物体的背景图片进行补全。而这一区域标记也可以通过视频帧间的类似传播到非关键帧上，从而所有的背景区域蒙版也扩展到了所有帧中，从而可以使用背景图片进行补全。

\section{算法细节}
在本节中我们将会介绍具体的算法和实现细节。

\begin{figure*}
\centering  \includegraphics[width=\linewidth]{Pictures/keyframe_seg2}\\
  \caption{关键帧中的人手去除例子。(a)图为在一次采集阶段中得到关键帧，其中通过运动跟踪得到的ROI区域显示为橙色矩形；(b)图是在二次采集阶段得到的对应图像；(c)图为自动计算的合成结果；(d) 图为用户指定笔刷已修正合成结果：(e)图为最终补全结果；(f)图为最终的蒙版标记图，其中红色表示$L(x)=0$（在补全图中使用在(a) 图中的颜色），绿色表示$L(x)=1$（使用(b) 图中的颜色）}\label{fig:kf_seg}
\end{figure*}

\subsection{ROI和关键帧选择}
实际上，我们的系统仅需要对被用户手部遮盖的物体区域进行操作，所以，正如\ref{sec:phases}节中的介绍，我们要求用户用一个矩形边界框松散的包围这一部分所关注的区域（如图\ref{fig:pipeline}(a)中的ROI）。正如\ref{sec:frame_prop}节中的假设，我们先验地假设拍摄物体的运动速度是相对较慢的，所以我们可以使用目前较为先进的方法\cite{liu2009beyond}，通过计算相邻帧间的光流对边界框进行跟踪。当然，我们也允许用户在任意一帧重新指定边界框，这一操作将会使接下去的帧追踪方法依此为初始值。

当所有的ROI都被指定后，我们的系统会根据物体的运动状况自动生成一系列关键帧，而关键帧的设置应该反映物体在物体外观发生显著变化的时刻。为了计算这些关键帧的位置，我们再次利用光流法来帮助计算。光流法能够捕捉到物体的运动方向和三维旋转方向，而这些变化会极大的影响物体的外观。我们仅在相邻帧的ROI 中计算光流。这一计算从前一个关键帧出发，设置一个阈值，当计算得到的累计平均光流速度超过这一阈值时，设置该帧为新的关键帧。具体地，定义从帧$t-1$到$t$的平均光流为$\|v_t\|$，当前的关键帧为$k_i$，则下一个关键帧$k_{i+1}$是使得$\sum_{t=k_i+1}^{k_{i+1}}\|v_t\|>T_v$的最小的$k_{i+1}$，这里$T_v$为事先指定的阈值（在实现中，我们使用$T_v=20$作为默认值）。

需要指出，提取关键帧在视频摘要的计算中是一个重要的问题（参见文献\cite{truong2007video}），这些方法最终是提取出一段视频的简单摘要，而本章的关键帧则是为了帮助在去除手部后对视频图像进行插值处理。

\subsection{透视模式及吸附算法}
一种直接的透视模式的界面，就是将在二次采集中的摄像头得到图片实时地同一次采集中的关键帧使用某一参数进行半透明混合重叠显示（如图\ref{fig:opinon_skinning}左图）。但是这种方法可能使得用户不太容易分辨二次采集与一次采集关键帧图片的差别。所以我们加入了其边缘图，即将两次采集的图片的边缘图重叠显示。我们发现，使用这一额外窗口显示可以极大地帮助用户，使其得到令人满意的对齐图片。

我们的系统并不需要完全精确的图片对齐操作，在实际操作过程中，图片的精确对齐也是极为困难的（见图\ref{fig:opinon_skinning}）。为了降低用户的对齐负担，我们在二次采集阶段对系统设计了一种特性，即吸附算法。具体地，我们实时地计算关键帧的ROI与二次采集中的摄像头得到的图片间的光流，并将其进行透视模式的显示。由于在两次采集中的人手处于不同位置，为了降低人手的干扰，我们对光流在每个像素使用两种图片颜色的差异进行加权。当两次采集的图片中的物体位置和方向都足够接近时（即满足光流法中的小范围移动假设），二次采集中实时的图片的ROI 区域将使用Warp手段变换以吸附到一次采集的关键帧上，这样就产生出较为精确的对齐结果。

为了验证对齐的精确性，我们的系统实时计算两张图片的SIFT特征\cite{lowe1999object}的匹配情况，我们认为当匹配到的特征见的平均距离小于一个阈值（系统中设定为3个像素）时，即得到一个良好的对齐结果。当然，SIFT适用的情况是物体的表面有较为明显的特征如纹理等，我们实验的例子显示，这一判断标准是合理和合适的。对于一些只有很少量SIFT特征的物体，本章的系统暂时不能得到较为合理的对齐结果。对于这类物体，可以采用一些其他的匹配技术，如物体的轮廓匹配等进行设计，而这些技术可以很容易的加入到我们的系统中。

\subsection{人手分割和去除}
对于在ROI区域之外的人体或阴影部分，我们可以直接的利用前面介绍的背景笔刷和静态背景图片直接恢复出来（即直接将对应像素的颜色值拷贝到非ROI区域的对应位置），所以在这一小节主要关注在ROI 中分割出人手区域并将其去除。

对于一帧给定的关键帧$k_i$，我们将其对于的ROI表示为$R_i$（如图\ref{fig:pipeline}(a)），其对应的二次采集得到对齐后的图像记为$R_i^l$，我们的目标是在$R_i^l$的辅助下，对$R_i$中去除被人手部遮挡的区域，并补全这一区域以得到完整的物体图像。为了达成这一目标，我们的系统使用了一种自动的算法并同样也提供了一种交互的工具以辅助打到目标。

由于对每一帧的操作都是相同的，为了简化标记，我们不显示关键帧的序号$i$。我们假设$R^l$已经通过光流法的变换对齐到了$R$，此时问题可以变换为图像的标记合成问题，即最终合成的图片的每一个像素$C_x$的颜色仅有2种可能，即$R_x$或者$R_x^l$。一般地，由于两张图片已经对齐，如果像素$x$位置在$R$和$R^l$中都没有被人手遮挡，则其对应的颜色基本一致，即$R_x\approx R_x^l$，我们指定$C_x=R_x$ 以减小对$R$的改变。另一方面，如果$x$在$R$或$R^l$两者之一中被人手遮挡，则$R_x$和$R_x^l$的颜色差异会非常巨大。此时我们使用静态背景图片来进一步辅助判断此时哪一块区域被遮挡。最终，如果遮挡发生在$R$，则指定$C_x=R_x^l$以重建出物体在该像素位置的颜色。

具体地，对于每一个像素$R_x$，我们计算2个颜色概率：$x$处于未遮挡区域（前景）的概率$p^f(x)$，以及$x$处于遮挡区域或者背景区域的概率$p^o(x)$。我们通过计算2张图片像素的差异，当$\|R_x-R_x^l\|^2<\delta$（其中$\delta$为一个很小的阈值参数，本章实验中取$\delta=0.05$），即差异较小时，将这些像素点做为初始前景高可信度点集，然后训练出一个高斯混合概率模型（GMM）$G^f$，类似地可以计算出非前景的高斯混合概率模型$G^o$。则我们计算前文提到的概率就可以使用这2个概率模型，即$p^f(x)=G^f(R_x)$，$p^o(x)=G^o(x)$。

\textbf{能量优化} 为了使得最终的合成图像的标记对于噪声和图像偏色的干扰在空间上是连贯和鲁棒的，我们使用类似于photomontage\cite{agarwala2004interactive}中的框架，用能量优化的方式来求解这一标记问题。具体地，我们需要最小化下面这一能量泛函：
\begin{equation}\label{equ:energy_composition}
  E(L)=\sum_xE_d(x,L(x))+\lambda \sum_{x,y}E_s(x,y,L(x),L(y)),
\end{equation}
其中$L(x)$为像素$x$的二元标记，即若$L(x)=0$则表示$C_x=R_x$，$L(x)=1$则表示$C_x=R_x^l$。$\lambda$为加权系数以平衡两个能量项（本章系统中设置$\lambda =0.5$）。$E_d(x,L(x))$为数据项能量，表示像素$x$被标记为$L(x)$的能量，具体定义为
\begin{equation}\label{equ:dataterm}
   E_d(x,L(x))=\left\{ \begin{array}{ll}
p^o(x)/( p^f(x)+p^o(x)) & L(x)=0,\\
p^f(x)/( p^f(x)+p^o(x)) & L(x)=1.
\end{array}\right.
\abovedisplayskip=3pt
\belowdisplayskip=3pt
\end{equation}
而式\ref{equ:energy_composition}光滑项$E_s(x,y,L(x),L(y))$的作用则是使得相邻像素间的标记是较为光滑的变化的。我们使用在photomontage\cite{agarwala2004interactive}中的“颜色匹配程度”标准来计算这一项的值，即当$L(x)\neq L(y)$时，定义
\begin{equation}\label{eqn:neighbor}
E_s(x,y,L(x),L(y))=\|R_x-R^l_y\|+\|R_y-R^l_x\|,
\abovedisplayskip=3pt
\belowdisplayskip=3pt
\end{equation}
否则，定义$E_s(x,y,L(x),L(y)=0$。

我们使用GraphCut优化算法\cite{boykov2006graph}对式\ref{equ:energy_composition}进行求解，然后生成图片合成补全后的结果。如果用户对这一结果满意，系统将继续处理下一关键帧，否则，用户可以通过笔刷工具指定若干像素区域为硬约束条件继续求解能量优化问题。如图\ref{fig:kf_seg}(c)中所示，自动算法存在少量错误的地方。为了修复这一问题，用户在图片上用红色笔刷指定了一些硬约束（对应的像素位置$L(x)=0$），如图\ref{fig:kf_seg}(d)。我们的系统可以实时的刷新出重新优化求解式\ref{equ:energy_composition}的结果。而最终的效果如图\ref{fig:kf_seg}(e)所示，已完成这一关键帧的去除人手工作。

需要指出的是，未被遮挡的背景像素（即非物体像素）$R_x$会在模型$G^f$和$G^o$中同时被加入训练，所以在这些像素上，两个概率$p^f(x)$和$p^o(x)$的值都较大，而数据项$E_d$此时不会偏向其中任何一方。这一问题在我们的应用中并不是一个缺陷，这是因为我们最终只需要去除掉人手部分的遮挡，而由于有光滑项能量的更大作用，我们可以使得最终的合成能够得到光滑无缝隙地结果。如图\ref{fig:kf_seg}(f)所示，虽然我们优化得到的标记函数$L(x)$并没有准确分割出物体或者人手，但是最终的合成结果却是足够优秀的。

\begin{figure*}
\centering  \includegraphics[width=\linewidth]{Pictures/temporal2}\\
  \caption{时序传播的例子。(a)图为第100帧的去除手部后的合成结果。(b)图为第100帧的物体蒙版（红色）和手部蒙版（绿色）。(c) 图为第115帧的去除手部结果。(d)图为第155帧的蒙版显示。(e)-(j) 图为通过时序传播自动计算得到的第102,104,107,108,111,113帧的结果图。}\label{fig:temporal}
\end{figure*}

\subsection{时序传播}\label{sec:frame_prop}
当两个相邻的关键帧$k_1$和$k_2$的图像补全操作完成后，记其对应的结果为$C_{k_1}$和$C_{k_2}$，我们的系统将会使用插值的方法计算出两个关键帧之间的任意一帧$j, k_1<j<k_2$，去除人手的图像。

为了达到这一目标，我们首先在干净的背景图片辅助下生成关键帧$k_1$的手部蒙版（mask）$M_{k_1}^{hand}$和物体未被遮挡区域的蒙版$M_{k_1}^{obj}$。具体地手部蒙版可以如下计算：
\begin{equation}\label{eqn_handmask}
M^{hand}_{k_1}(x)=T_h(|R_{k_1}(x)-B(x)|)\,\&\,T_h(|R_{k_1}(x)-C_{k_1}(x)|),
\abovedisplayskip=3pt
\belowdisplayskip=3pt
\end{equation}
其中$T_h(\epsilon)$为阶跃函数，即当$\epsilon >T_c$时，$T_h(\epsilon)=1$；否则$T_h(\epsilon)=0$。这里，$T_c$为一个预先设定的颜色阈值（$T_c=0.1$在本章系统中）。而物体未被遮挡区域的蒙版则利用下式计算：
\begin{equation}\label{eqn_objmask}
M^{obj}_{k_1}(x)=T_h(|R_{k_1}(x)-B(x)|)-M^{hand}_{k_1}(x).
\abovedisplayskip=3pt
\belowdisplayskip=3pt
\end{equation}
图\ref{fig:temporal}(b)和(d)均显示了两种蒙版$M^{obj}$和$M^{hand}$。

然后，我们计算出在物体蒙版$M_{k_1}^{obj}$内的$R_{k_1}$到$R_j$ 的光流，将这一光流场可以通过外插法，从合成图像$C_{k_1}$和$M_{k_1}^{hand}$外插到帧$j$上，记其为$C'_{k_1}$和$M'^{hand}_{k_1}$。类似地，我们计算出从关键帧$k_2$得到的$C'_{k_2}$和$M'^{hand}_{k_2}$。然后我们用线性插值的方法，插值$C'_{k_1}$和$C'_{k_2}$，生成帧$j$的合成物体图像$C_j$，同时计算帧$j$的手部蒙版为$M_j^{hand}=M'^{hand}_{k_1}\bigcap M'^{hand}_{k_2}$。最终，为了去除帧$j$ 的人手，我们使用Poisson混合\cite{perez2003poisson}的方法将人手蒙版区域$M_j^{hand}$与$R_j$ 的ROI进行无缝混合合成，得到如图\ref{fig:temporal}下中的结果。

根据式子\ref{eqn_handmask}和式子\ref{eqn_objmask}，蒙版的计算是逐像素计算的。理论上，蒙版可以使用能量优化如graphcut类似的办法进行更好的计算。然而，在实验中，我们发现并不需要非常精确的物体和手部蒙版就能得到令人满意的动画结果。而未遮挡物体蒙版主要是用来估计运动，所以该蒙版中小的错误并不会影响最终的结果。对于手部蒙版$M_j^{hand}$，我们人为地扩大一点以消除人手部附近的阴影对结果造成的影响。使用本章中的逐像素的计算方式，能够给用户迅速的视觉反馈，这使得用户在整个动画制作的过程更加流畅。当场景中的物体的有太多的阴影时（如图\ref{}中的魔方例子），光流的计算就会不很稳定，用户可以用笔刷大致圈出这一阴影

\section{实验结果与讨论}

\section{本章小结}


